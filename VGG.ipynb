{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-16 Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install msgpack\n",
    "!{sys.executable} -m pip install split-folders==0.2.0\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install tensorflow\n",
    "!{sys.executable} -m pip install keras\n",
    "!{sys.executable} -m pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Here we have all the packages needed to create our Neural Net\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D,GlobalAveragePooling2D,AveragePooling2D,Input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "import itertools\n",
    "import h5py\n",
    "from keras.utils.io_utils import HDF5Matrix\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Preprocessing (do once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "file_name='foodimages.zip'\n",
    "zipp=ZipFile(file_name,mode='r')\n",
    "zipp.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import split_folders\n",
    "split_folders.ratio('yum',output='output',ratio=(.8,.1,.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data (Start here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_dir='output/train'\n",
    "val_image_dir='output/val'\n",
    "test_image_dir='output/test'\n",
    "image_size=(224,224)\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Unaugmented Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80800 images belonging to 101 classes.\n",
      "Found 10100 images belonging to 101 classes.\n",
      "Found 10100 images belonging to 101 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = False,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0,\n",
    "width_shift_range = 0,\n",
    "height_shift_range=0,\n",
    "rotation_range=0)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "train_image_dir,\n",
    "target_size = (image_size[0], image_size[1]),\n",
    "batch_size = batch_size, \n",
    "class_mode = \"categorical\")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "val_image_dir,\n",
    "target_size = (image_size[0], image_size[1]),\n",
    "batch_size = batch_size, \n",
    "class_mode = \"categorical\")\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "test_image_dir,\n",
    "target_size = (image_size[0], image_size[1]),\n",
    "batch_size = batch_size, \n",
    "class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augemented Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80800 images belonging to 101 classes.\n"
     ]
    }
   ],
   "source": [
    "aug_gen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = False,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.25,\n",
    "width_shift_range = 0.2,\n",
    "height_shift_range=0.2,\n",
    "rotation_range=30)\n",
    "\n",
    "a_train_generator = aug_gen.flow_from_directory(\n",
    "train_image_dir,\n",
    "target_size = (image_size[0], image_size[1]),\n",
    "batch_size = batch_size, \n",
    "class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load VGG (Base) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model=VGG16(weights='imagenet',include_top=False,input_tensor=Input(shape=(64,64,3),name='input_image'),classes=101)\n",
    "base_model=VGG16(weights='imagenet',include_top=False,input_tensor=Input(shape=(224,224,3),name='input_image'),classes=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "# x=Flatten()(x)\n",
    "x=Dense(1024,activation='relu')(x)\n",
    "x=Dense(1024,activation='relu')(x)\n",
    "x=Dense(512,activation='relu')(x)\n",
    "predictions=Dense(101,activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model_1=Model(inputs=base_model.input,outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model_1.compile(optimizer=Adam(lr=.0001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "632/632 [==============================] - 2401s 4s/step - loss: 4.1617 - acc: 0.0608 - val_loss: 3.3060 - val_acc: 0.1951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8024020710>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model_1.fit_generator(train_generator,\n",
    "               steps_per_epoch=632,\n",
    "               epochs=1,\n",
    "               verbose=1,\n",
    "               validation_data=val_generator,\n",
    "               validation_steps=batch_size,\n",
    "               shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(name_json, name_weights,model):\n",
    "    model_json=model.to_json()\n",
    "    with open(name_json,'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(name_weights)\n",
    "    print('saved model to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load json and create model\n",
    "def load_model(name_json,name_weights):\n",
    "    json_file=open(name_json,'r')\n",
    "    loaded_model_json=json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model=model_from_json(loaded_model_json)\n",
    "    #load weights into new model\n",
    "    loaded_model.load_weights(name_weights)\n",
    "    print('Loaded model from disk')\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training continues..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "632/632 [==============================] - 2608s 4s/step - loss: 2.6654 - acc: 0.3272 - val_loss: 2.1546 - val_acc: 0.4447\n",
      "Epoch 2/2\n",
      "632/632 [==============================] - 2513s 4s/step - loss: 1.9260 - acc: 0.4974 - val_loss: 1.7630 - val_acc: 0.5417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7027310dd8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.compile(optimizer=Adam(lr=.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "loaded_model.fit_generator(train_generator,\n",
    "               steps_per_epoch=632,\n",
    "               epochs=2,\n",
    "               verbose=1,\n",
    "               validation_data=val_generator,\n",
    "               validation_steps=batch_size,\n",
    "               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model to disk\n"
     ]
    }
   ],
   "source": [
    "save_model('vgg_model_1_1.json','vgg_model_1_1_weights.h5',loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "vgg_model_1_1=load_model('vgg_model_1_1.json','vgg_model_1_1_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "632/632 [==============================] - 2134s 3s/step - loss: 1.5294 - acc: 0.5936 - val_loss: 1.5565 - val_acc: 0.5924\n",
      "Epoch 2/5\n",
      "632/632 [==============================] - 624s 988ms/step - loss: 1.2932 - acc: 0.6516 - val_loss: 1.4588 - val_acc: 0.6308\n",
      "Epoch 3/5\n",
      "632/632 [==============================] - 622s 984ms/step - loss: 1.1085 - acc: 0.6960 - val_loss: 1.3376 - val_acc: 0.6533\n",
      "Epoch 4/5\n",
      "632/632 [==============================] - 621s 983ms/step - loss: 0.9603 - acc: 0.7321 - val_loss: 1.3129 - val_acc: 0.6725\n",
      "Epoch 5/5\n",
      "632/632 [==============================] - 622s 984ms/step - loss: 0.8156 - acc: 0.7701 - val_loss: 1.2669 - val_acc: 0.6829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7ea4d98748>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model_1_1.compile(optimizer=Adam(lr=.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "vgg_model_1_1.fit_generator(train_generator,\n",
    "               steps_per_epoch=632,\n",
    "               epochs=5,\n",
    "               verbose=1,\n",
    "               validation_data=val_generator,\n",
    "               validation_steps=batch_size,\n",
    "               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model to disk\n"
     ]
    }
   ],
   "source": [
    "save_model('vgg_model_1_1.json','vgg_model_1_1_weights.h5',vgg_model_1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "632/632 [==============================] - 625s 988ms/step - loss: 0.6906 - acc: 0.8013 - val_loss: 1.3028 - val_acc: 0.6877\n",
      "Epoch 2/10\n",
      "632/632 [==============================] - 624s 988ms/step - loss: 0.5810 - acc: 0.8301 - val_loss: 1.4755 - val_acc: 0.6666\n",
      "Epoch 3/10\n",
      "632/632 [==============================] - 623s 986ms/step - loss: 0.4923 - acc: 0.8544 - val_loss: 1.4129 - val_acc: 0.6728\n",
      "Epoch 4/10\n",
      "632/632 [==============================] - 624s 988ms/step - loss: 0.4087 - acc: 0.8763 - val_loss: 1.4170 - val_acc: 0.6887\n",
      "Epoch 5/10\n",
      "632/632 [==============================] - 624s 987ms/step - loss: 0.3338 - acc: 0.8983 - val_loss: 1.6071 - val_acc: 0.6854\n",
      "Epoch 6/10\n",
      "632/632 [==============================] - 624s 987ms/step - loss: 0.2819 - acc: 0.9116 - val_loss: 1.5458 - val_acc: 0.6950\n",
      "Epoch 7/10\n",
      "632/632 [==============================] - 625s 989ms/step - loss: 0.2417 - acc: 0.9244 - val_loss: 1.6669 - val_acc: 0.6880\n",
      "Epoch 8/10\n",
      "632/632 [==============================] - 625s 988ms/step - loss: 0.2132 - acc: 0.9329 - val_loss: 1.6310 - val_acc: 0.6950\n",
      "Epoch 9/10\n",
      "632/632 [==============================] - 625s 988ms/step - loss: 0.1759 - acc: 0.9436 - val_loss: 1.8703 - val_acc: 0.6818\n",
      "Epoch 10/10\n",
      "632/632 [==============================] - 624s 988ms/step - loss: 0.1732 - acc: 0.9445 - val_loss: 1.7598 - val_acc: 0.6907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e0ae190b8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model_1_1.fit_generator(train_generator,\n",
    "               steps_per_epoch=632,\n",
    "               epochs=10,\n",
    "               verbose=1,\n",
    "               validation_data=val_generator,\n",
    "               validation_steps=batch_size,\n",
    "               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model to disk\n"
     ]
    }
   ],
   "source": [
    "save_model('vgg_model_1_2.json','vgg_model_1_2_weights.h5',vgg_model_1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "632/632 [==============================] - 625s 988ms/step - loss: 0.1464 - acc: 0.9533 - val_loss: 1.7762 - val_acc: 0.6853\n",
      "Epoch 2/10\n",
      "632/632 [==============================] - 621s 983ms/step - loss: 0.1367 - acc: 0.9567 - val_loss: 1.8909 - val_acc: 0.6884\n",
      "Epoch 3/10\n",
      "632/632 [==============================] - 623s 986ms/step - loss: 0.1345 - acc: 0.9569 - val_loss: 1.7496 - val_acc: 0.6862\n",
      "Epoch 4/10\n",
      "632/632 [==============================] - 623s 987ms/step - loss: 0.1191 - acc: 0.9617 - val_loss: 1.9071 - val_acc: 0.6884\n",
      "Epoch 5/10\n",
      "632/632 [==============================] - 624s 987ms/step - loss: 0.1105 - acc: 0.9648 - val_loss: 2.0331 - val_acc: 0.6800\n",
      "Epoch 6/10\n",
      "632/632 [==============================] - 623s 986ms/step - loss: 0.1017 - acc: 0.9672 - val_loss: 1.7711 - val_acc: 0.6940\n",
      "Epoch 7/10\n",
      "632/632 [==============================] - 624s 988ms/step - loss: 0.1008 - acc: 0.9683 - val_loss: 1.8762 - val_acc: 0.6895\n",
      "Epoch 8/10\n",
      "632/632 [==============================] - 622s 984ms/step - loss: 0.0978 - acc: 0.9687 - val_loss: 2.0912 - val_acc: 0.6696\n",
      "Epoch 9/10\n",
      "632/632 [==============================] - 622s 984ms/step - loss: 0.0960 - acc: 0.9693 - val_loss: 1.9138 - val_acc: 0.6733\n",
      "Epoch 10/10\n",
      "632/632 [==============================] - 622s 984ms/step - loss: 0.0838 - acc: 0.9733 - val_loss: 2.1266 - val_acc: 0.6749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e0ac29780>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model_1_1.fit_generator(train_generator,\n",
    "               steps_per_epoch=632,\n",
    "               epochs=10,\n",
    "               verbose=1,\n",
    "               validation_data=val_generator,\n",
    "               validation_steps=batch_size,\n",
    "               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model to disk\n"
     ]
    }
   ],
   "source": [
    "save_model('vgg_model_1_3.json','vgg_model_1_3_weights.h5',vgg_model_1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweaking by adding Dropout Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model_2=load_model('vgg_models/vgg_model_1_3.json','vgg_models/vgg_model_1_3_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_image (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 101)               51813     \n",
      "=================================================================\n",
      "Total params: 16,866,213\n",
      "Trainable params: 16,866,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1=vgg_model_2.layers[-4]\n",
    "fc2=vgg_model_2.layers[-3]\n",
    "fc3=vgg_model_2.layers[-2]\n",
    "predictions=vgg_model_2.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout1=Dropout(.5)\n",
    "dropout2=Dropout(.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#Reconnect the layers\n",
    "x=dropout1(fc1.output)\n",
    "x=fc2(x)\n",
    "x=dropout2(x)\n",
    "x=fc3(x)\n",
    "predictors=predictions(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "vgg_model_2=Model(input=vgg_model_2.input,output=predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "632/632 [==============================] - 2440s 4s/step - loss: 0.3107 - acc: 0.9051 - val_loss: 1.6107 - val_acc: 0.6995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f299131ea20>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model_2.compile(optimizer=Adam(lr=.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "vgg_model_2.fit_generator(train_generator,\n",
    "               steps_per_epoch=632,\n",
    "               epochs=1,\n",
    "               verbose=1,\n",
    "               validation_data=val_generator,\n",
    "               validation_steps=batch_size,\n",
    "               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model to disk\n"
     ]
    }
   ],
   "source": [
    "save_model('vgg_models/vgg_model_2.json','vgg_models/vgg_model_2_weights.h5',vgg_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "632/632 [==============================] - 622s 985ms/step - loss: 0.2215 - acc: 0.9309 - val_loss: 1.6566 - val_acc: 0.6982\n",
      "Epoch 2/6\n",
      "632/632 [==============================] - 622s 985ms/step - loss: 0.1997 - acc: 0.9389 - val_loss: 1.6598 - val_acc: 0.6921\n",
      "Epoch 3/6\n",
      "632/632 [==============================] - 620s 981ms/step - loss: 0.1791 - acc: 0.9462 - val_loss: 1.7189 - val_acc: 0.6970\n",
      "Epoch 4/6\n",
      "632/632 [==============================] - 621s 982ms/step - loss: 0.1609 - acc: 0.9510 - val_loss: 1.8109 - val_acc: 0.6858\n",
      "Epoch 5/6\n",
      "632/632 [==============================] - 623s 985ms/step - loss: 0.1454 - acc: 0.9559 - val_loss: 1.7514 - val_acc: 0.6972\n",
      "Epoch 6/6\n",
      "632/632 [==============================] - 622s 984ms/step - loss: 0.1378 - acc: 0.9580 - val_loss: 1.8857 - val_acc: 0.6734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2972580588>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model_2.fit_generator(train_generator,\n",
    "               steps_per_epoch=632,\n",
    "               epochs=6,\n",
    "               verbose=1,\n",
    "               validation_data=val_generator,\n",
    "               validation_steps=batch_size,\n",
    "               shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "vgg_model_3=load_model('vgg_models/vgg_model_2.json','vgg_models/vgg_model_2_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "632/632 [==============================] - 3130s 5s/step - loss: 0.9154 - acc: 0.7518 - val_loss: 1.3649 - val_acc: 0.6885\n",
      "Epoch 2/5\n",
      "632/632 [==============================] - 1049s 2s/step - loss: 0.8199 - acc: 0.7765 - val_loss: 1.2612 - val_acc: 0.7081\n",
      "Epoch 3/5\n",
      "632/632 [==============================] - 1053s 2s/step - loss: 0.7569 - acc: 0.7899 - val_loss: 1.2458 - val_acc: 0.7174\n",
      "Epoch 4/5\n",
      "632/632 [==============================] - 1046s 2s/step - loss: 0.7022 - acc: 0.8039 - val_loss: 1.2595 - val_acc: 0.7075\n",
      "Epoch 5/5\n",
      "632/632 [==============================] - 1041s 2s/step - loss: 0.6647 - acc: 0.8141 - val_loss: 1.2781 - val_acc: 0.7075\n",
      "saved model to disk\n"
     ]
    }
   ],
   "source": [
    "vgg_model_3.compile(optimizer=Adam(lr=.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "vgg_model_3.fit_generator(a_train_generator,\n",
    "               steps_per_epoch=632,\n",
    "               epochs=5,\n",
    "               verbose=1,\n",
    "               validation_data=val_generator,\n",
    "               validation_steps=batch_size,\n",
    "               shuffle=True)\n",
    "save_model('vgg_models/vgg_model_3.json','vgg_models/vgg_model_3_weights.h5',vgg_model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary to get from keras prediction to label name. (Only need to do once!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map=(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dictionary={y:x for x,y in label_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apple_pie'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dictionary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=open('label_dictionary.pkl','wb')\n",
    "pickle.dump(my_dictionary,output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file=open('label_dictionary.pkl','rb')\n",
    "try_again=pickle.load(pkl_file)\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apple_pie'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_again[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary for food to calories. (Only need to do once!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('food_names.txt','w')\n",
    "for food in label_map:\n",
    "    file.write(food)\n",
    "    file.write(' '+'\\n')\n",
    "#     file.write('/n')\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
